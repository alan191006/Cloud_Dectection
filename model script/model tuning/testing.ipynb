{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/home/alan/Documents/Cloud_Detection/neural network/c_unet_1649683131.7209947.pth\"\n",
    "r\"\"\"\n",
    "RED_PATH = r\"C:\\Users\\hdmqu\\Documents\\LUX Aerobot\\Dataset\\Full dataset\\95red_filter\\\\\"\n",
    "GREEN_PATH = r\"C:\\Users\\hdmqu\\Documents\\LUX Aerobot\\Dataset\\Full dataset\\95green_filter\\\\\"\n",
    "BLUE_PATH = r\"C:\\Users\\hdmqu\\Documents\\LUX Aerobot\\Dataset\\Full dataset\\95blue_filter\\\\\"\n",
    "NIR_PATH = r\"C:\\Users\\hdmqu\\Documents\\LUX Aerobot\\Dataset\\Full dataset\\95nir_filter\\\\\"\n",
    "GT_PATH = r\"C:\\Users\\hdmqu\\Documents\\LUX Aerobot\\Dataset\\Full dataset\\95gt_filter\\\\\"\n",
    "\"\"\"\n",
    "\n",
    "RED_PATH = \"/home/alan/Documents/cloud_detection_data/95Cloud/95red/\"\n",
    "GREEN_PATH = \"/home/alan/Documents/cloud_detection_data/95Cloud/95green/\"\n",
    "BLUE_PATH = \"/home/alan/Documents/cloud_detection_data/95Cloud/95blue/\"\n",
    "NIR_PATH = \"/home/alan/Documents/cloud_detection_data/95Cloud/95nir/\"\n",
    "GT_PATH = \"/home/alan/Documents/cloud_detection_data/95Cloud/95gt/\"\n",
    "\n",
    "\n",
    "r_dir = Path(RED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cloud images:\t 2021\n",
      "Less cloud images:\t 1960\n",
      "More cloud images:\t 1189\n",
      "Full cloud images:\t 3004\n",
      "Total images:\t\t 8174\n"
     ]
    }
   ],
   "source": [
    "#   0%      1 - 30%    30 - 70%    70 - 100%\n",
    "no_cloud, less_cloud, more_cloud, full_cloud = [], [], [], []\n",
    "\n",
    "low_threshold = 384*384 * 0.3\n",
    "high_threshold = 384*384 * 0.7\n",
    "\n",
    "u = os.listdir(GT_PATH)\n",
    "\n",
    "for file in u[int(len(u)/2):]:\n",
    "    img = cv2.imread(GT_PATH + file)\n",
    "    \n",
    "    occurrences = np.count_nonzero(img[:, :, 0] == 255)\n",
    "\n",
    "    if occurrences == 0:\n",
    "        no_cloud.append(file)\n",
    "        continue\n",
    "    elif occurrences < low_threshold:\n",
    "        less_cloud.append(file)\n",
    "        continue\n",
    "    elif occurrences < high_threshold:\n",
    "        more_cloud.append(file)\n",
    "    else:\n",
    "        full_cloud.append(file)\n",
    "\n",
    "print(\"No cloud images:\\t\", len(no_cloud))\n",
    "print(\"Less cloud images:\\t\", len(less_cloud))\n",
    "print(\"More cloud images:\\t\", len(more_cloud))\n",
    "print(\"Full cloud images:\\t\", len(full_cloud))\n",
    "print(\"Total images:\\t\\t\", int(len(os.listdir(GT_PATH))/2)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_path(list):\n",
    "    for i in range(len(list)):\n",
    "        list[i] = RED_PATH + list[i].replace(\"gt\", \"red\")\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cloud_list = to_path(no_cloud)\n",
    "less_cloud_list = to_path(less_cloud)\n",
    "more_cloud_list = to_path(more_cloud)\n",
    "full_cloud_list = to_path(full_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, r_dir, g_dir, b_dir, nir_dir, gt_dir, file_list):\n",
    "        super().__init__()\n",
    "        self.files = [self.combine_files(f, g_dir, b_dir, nir_dir, gt_dir) for f in file_list if not os.path.isdir(f)]\n",
    "        \n",
    "    def combine_files(self, r_file: Path, g_dir, b_dir, nir_dir, gt_dir):\n",
    "        files = {\n",
    "            'red': r_file, \n",
    "            'green': r_file.replace('red', 'green'),\n",
    "            'blue': r_file.replace('red', 'blue'), \n",
    "            'nir': r_file.replace('red', 'nir'),\n",
    "            'gt': r_file.replace('red', 'gt')\n",
    "        }\n",
    "        return files\n",
    "                                       \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "     \n",
    "    def open_as_array(self, idx, invert=False, include_nir=False):\n",
    "        raw_rgb = np.stack([\n",
    "            np.array(Image.open(self.files[idx]['red'])),\n",
    "            np.array(Image.open(self.files[idx]['green'])),\n",
    "            np.array(Image.open(self.files[idx]['blue'])),\n",
    "        ], axis=2)\n",
    "        if include_nir:\n",
    "            nir = np.expand_dims(np.array(Image.open(self.files[idx]['nir'])), 2)\n",
    "            raw_rgb = np.concatenate([raw_rgb, nir], axis=2)\n",
    "        if invert:\n",
    "            raw_rgb = raw_rgb.transpose((2,0,1))\n",
    "        return (raw_rgb / np.iinfo(raw_rgb.dtype).max) # normalized\n",
    "\n",
    "\n",
    "    def open_mask(self, idx, add_dims=False):\n",
    "        raw_mask = np.array(Image.open(self.files[idx]['gt']))\n",
    "        raw_mask = np.where(raw_mask==255, 1, 0)\n",
    "        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.open_as_array(idx, invert=True, include_nir=True), dtype=torch.float32)\n",
    "        y = torch.tensor(self.open_mask(idx, add_dims=False), dtype=torch.long)\n",
    "        return x, y\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Dataset class with {self.__len__()} files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset class with 2021 files\n",
      "Dataset class with 1960 files\n",
      "Dataset class with 1189 files\n",
      "Dataset class with 3004 files\n"
     ]
    }
   ],
   "source": [
    "no_cloud_data =  CloudDataset(RED_PATH, GREEN_PATH, BLUE_PATH, NIR_PATH, GT_PATH, no_cloud_list)\n",
    "less_cloud_data =  CloudDataset(RED_PATH, GREEN_PATH, BLUE_PATH, NIR_PATH, GT_PATH, less_cloud_list)\n",
    "more_cloud_data =  CloudDataset(RED_PATH, GREEN_PATH, BLUE_PATH, NIR_PATH, GT_PATH, more_cloud_list)\n",
    "full_cloud_data =  CloudDataset(RED_PATH, GREEN_PATH, BLUE_PATH, NIR_PATH, GT_PATH, full_cloud_list)\n",
    "\n",
    "print(no_cloud_data)\n",
    "print(less_cloud_data)\n",
    "print(more_cloud_data)\n",
    "print(full_cloud_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: torch.Size([4, 384, 384])\n",
      "Mask: torch.Size([384, 384])\n"
     ]
    }
   ],
   "source": [
    "# Single input example\n",
    "x, y = no_cloud_data[0]\n",
    "print(f'Image: {x.shape}')\n",
    "print(f'Mask: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class depthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, nin, nout):\n",
    "        super(depthwiseSeparableConv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(nin, nin, kernel_size=3, padding=1, groups=nin)\n",
    "        self.pointwise = nn.Conv2d(nin, nout, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C_UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = self.contract_block(in_channels, 32)\n",
    "        self.conv2 = self.contract_block(32, 64)\n",
    "        self.conv3 = self.contract_block(64, 128)\n",
    "\n",
    "        self.upconv3 = self.expand_block(128, 64, 3, 1)\n",
    "        self.upconv2 = self.expand_block(64, 32, 3, 1)\n",
    "        self.upconv1 = self.expand_block(32, out_channels, 3, 1)\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # downsampling part\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "\n",
    "        upconv3 = self.upconv3(conv3)\n",
    "        upconv2 = self.upconv2(upconv3)\n",
    "        upconv1 = self.upconv1(upconv2)\n",
    "\n",
    "        out = self.out(upconv1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def contract_block(self, in_channels, out_channels):\n",
    "        contract = nn.Sequential(\n",
    "            depthwiseSeparableConv(in_channels, out_channels),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        return contract\n",
    "\n",
    "\n",
    "    def expand_block(self, in_channels, out_channels, kernel_size, padding):\n",
    "        expand = nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            torch.nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1) \n",
    "        )\n",
    "        return expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n"
     ]
    }
   ],
   "source": [
    "def my_collate(batch):\n",
    "    batch = list(filter (lambda x:torch.sum(x[0]).item() != 0, batch))\n",
    "    if len(batch) == 0:\n",
    "        print(\"DOOOOO\")\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKER = 0\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using {DEVICE} device.\")\n",
    "\n",
    "no_cloud_loader = DataLoader(no_cloud_data, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER, collate_fn=my_collate)\n",
    "less_cloud_loader = DataLoader(less_cloud_data, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER, collate_fn=my_collate)\n",
    "more_cloud_loader = DataLoader(more_cloud_data, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER, collate_fn=my_collate)\n",
    "full_cloud_loader = DataLoader(full_cloud_data, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C_UNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): depthwiseSeparableConv(\n",
       "      (depthwise): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
       "      (pointwise): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): depthwiseSeparableConv(\n",
       "      (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "      (pointwise): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): depthwiseSeparableConv(\n",
       "      (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "      (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (upconv3): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       "  (upconv2): Sequential(\n",
       "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       "  (upconv1): Sequential(\n",
       "    (0): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(2, 2, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Conv2d(2, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = C_UNet(4, 2)\n",
    "model.to(DEVICE)\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "param_to_prune = (\n",
    "    (model.conv1[0].depthwise, \"weight\"),\n",
    "    (model.conv1[0].pointwise, \"weight\"),\n",
    "\n",
    "    (model.conv2[0].depthwise, \"weight\"),\n",
    "    (model.conv2[0].pointwise, \"weight\"),\n",
    "\n",
    "    (model.conv3[0].depthwise, \"weight\"),\n",
    "    (model.conv3[0].pointwise, \"weight\"),\n",
    "\n",
    "    (model.upconv3[0], \"weight\"),\n",
    "    (model.upconv3[3], \"weight\"),\n",
    "\n",
    "    (model.upconv2[0], \"weight\"),\n",
    "    (model.upconv2[3], \"weight\"),\n",
    "\n",
    "    (model.upconv1[0], \"weight\"),\n",
    "    (model.upconv1[3], \"weight\"),\n",
    "\n",
    "    (model.out[0], \"weight\")\n",
    ")\n",
    "\n",
    "from torch.nn.utils import prune\n",
    "\n",
    "prune.global_unstructured(\n",
    "    param_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.15,\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "def get_accuracy(data_loader, model):\n",
    "    acc, rec, pre, f1 = [], [], [], []\n",
    "\n",
    "    accuracy = torchmetrics.Accuracy()\n",
    "    recall = torchmetrics.Recall()\n",
    "    precision = torchmetrics.Precision()\n",
    "    f1_score = torchmetrics.F1Score()\n",
    "\n",
    "\n",
    "    for images, targets in tqdm(data_loader):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Get predictions\n",
    "            images = images.to(DEVICE).to(torch.float32)\n",
    "            targets = targets.to(DEVICE)\n",
    "            predictions = model(images)[:, 1, :, :].to(torch.float32)\n",
    "\n",
    "            acc.append(accuracy(predictions, targets))\n",
    "            rec.append(recall(predictions, targets))\n",
    "            pre.append(precision(predictions, targets))\n",
    "            f1.append(f1_score(predictions, targets))\n",
    "\n",
    "    #return round(np.mean(acc), 4), round(np.mean(rec)), round(np.mean(pre), 4), round(np.mean(f1), 4)\n",
    "    return np.mean(acc), np.mean(rec), np.mean(pre), np.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [05:39<00:00,  5.30s/it]\n",
      "100%|██████████| 62/62 [05:19<00:00,  5.16s/it]\n",
      "100%|██████████| 38/38 [03:24<00:00,  5.37s/it]\n",
      "100%|██████████| 94/94 [07:59<00:00,  5.10s/it]\n"
     ]
    }
   ],
   "source": [
    "no_acc, no_rec, no_pre, no_f1 = get_accuracy(no_cloud_loader, model)\n",
    "less_acc, less_rec, less_pre, less_f1 = get_accuracy(less_cloud_loader, model)\n",
    "more_acc, more_rec, more_pre, more_f1 = get_accuracy(more_cloud_loader, model)\n",
    "full_acc, full_rec, full_pre, full_f1 = get_accuracy(full_cloud_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tAccuracy\tRecall\t\tPrecision\tF1\n",
      "No cloud:\t0.985948920249939\t0.0\t0.0\t0.0\n",
      "Less cloud:\t0.9404667019844055\t0.492559552192688\t0.6950187087059021\t0.5668129324913025\n",
      "More cloud:\t0.7864971160888672\t0.6283211708068848\t0.9094123840332031\t0.7393919229507446\n",
      "Full cloud:\t0.7800031900405884\t0.7760016322135925\t0.9913796782493591\t0.8693432807922363\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t\\tAccuracy\\tRecall\\t\\tPrecision\\tF1\")\n",
    "print(f\"No cloud:\\t{no_acc}\\t{no_rec}\\t{no_pre}\\t{no_f1}\")\n",
    "print(f\"Less cloud:\\t{less_acc}\\t{less_rec}\\t{less_pre}\\t{less_f1}\")\n",
    "print(f\"More cloud:\\t{more_acc}\\t{more_rec}\\t{more_pre}\\t{more_f1}\")\n",
    "print(f\"Full cloud:\\t{full_acc}\\t{full_rec}\\t{full_pre}\\t{full_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloud thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "thin_cloud, thick_cloud = [], []\n",
    "\n",
    "thickness_threshold = (0.46875, 0.46875, 0.46875, 0.46875)\n",
    "\n",
    "for i in range(len(full_cloud_data)):\n",
    "\n",
    "    x, y = full_cloud_data[i]\n",
    "    out = cv2.inRange(torch.permute(x, (1, 2, 0)).numpy(), thickness_threshold, (1, 1, 1, 1))\n",
    "\n",
    "    try:\n",
    "        IoU = np.sum(np.logical_and(out, y.numpy())) / np.sum(np.logical_or(out, y.numpy()))\n",
    "    except ZeroDivisionError:\n",
    "        thin_cloud.append(full_cloud_list[i])\n",
    "        continue\n",
    "\n",
    "    if IoU > 0.5:\n",
    "        thick_cloud.append(full_cloud_list[i])\n",
    "    else:\n",
    "        thin_cloud.append(full_cloud_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2890\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "print(len(thin_cloud))\n",
    "print(len(thick_cloud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "thin_cloud_data =  CloudDataset(RED_PATH, GREEN_PATH, BLUE_PATH, NIR_PATH, GT_PATH, thin_cloud)\n",
    "thick_cloud_data =  CloudDataset(RED_PATH, GREEN_PATH, BLUE_PATH, NIR_PATH, GT_PATH, thick_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "thin_cloud_loader = DataLoader(thin_cloud_data, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER, collate_fn=my_collate)\n",
    "thick_cloud_loader = DataLoader(thick_cloud_data, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [06:24<00:00,  4.23s/it]\n",
      "100%|██████████| 4/4 [00:16<00:00,  4.06s/it]\n"
     ]
    }
   ],
   "source": [
    "thin_acc, thin_rec, thin_pre, thin_f1 = get_accuracy(thin_cloud_loader, model)\n",
    "thick_acc, thick_rec, thick_pre, thick_f1 = get_accuracy(thick_cloud_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tAccuracy\tRecall\t\tPrecision\tF1\n",
      "Thin cloud:\t0.7714474201202393\t0.7670773267745972\t0.9912219047546387\t0.8630764484405518\n",
      "Thick cloud:\t0.9971867799758911\t0.9984418749809265\t0.9986624121665955\t0.9985519647598267\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t\\tAccuracy\\tRecall\\t\\tPrecision\\tF1\")\n",
    "print(f\"Thin cloud:\\t{thin_acc}\\t{thin_rec}\\t{thin_pre}\\t{thin_f1}\")\n",
    "print(f\"Thick cloud:\\t{thick_acc}\\t{thick_rec}\\t{thick_pre}\\t{thick_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'no_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/alan/Documents/Cloud_Detection/model tuning/testing.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alan/Documents/Cloud_Detection/model%20tuning/testing.ipynb#ch0000023?line=0'>1</a>\u001b[0m \u001b[39m# data to plot\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/alan/Documents/Cloud_Detection/model%20tuning/testing.ipynb#ch0000023?line=1'>2</a>\u001b[0m acc_list \u001b[39m=\u001b[39m [no_acc, less_acc, more_acc, full_acc, thin_acc, thick_acc]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alan/Documents/Cloud_Detection/model%20tuning/testing.ipynb#ch0000023?line=2'>3</a>\u001b[0m rec_list \u001b[39m=\u001b[39m [no_rec, less_rec, more_rec, full_rec, thin_rec, thick_rec]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alan/Documents/Cloud_Detection/model%20tuning/testing.ipynb#ch0000023?line=3'>4</a>\u001b[0m pre_list \u001b[39m=\u001b[39m [no_pre, less_pre, more_pre, full_pre, thin_pre, thick_pre]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'no_acc' is not defined"
     ]
    }
   ],
   "source": [
    "# data to plot\n",
    "acc_list = [no_acc, less_acc, more_acc, full_acc, thin_acc, thick_acc]\n",
    "rec_list = [no_rec, less_rec, more_rec, full_rec, thin_rec, thick_rec]\n",
    "pre_list = [no_pre, less_pre, more_pre, full_pre, thin_pre, thick_pre]\n",
    "f1_list = [no_f1, less_f1, more_f1, full_f1, thin_f1, thick_f1]\n",
    "\n",
    "name_list = (\"0% cloud\", \n",
    "             \"1 - 30% cloud\", \n",
    "             \"30 - 70% cloud\",\n",
    "             \"71 - 100% cloud\",\n",
    "             \"thin cloud\",\n",
    "             \"thick cloud\")\n",
    "\n",
    "n_groups = len(name_list)\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "plt.rcParams[\"figure.figsize\"] = (30, 16)\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.6\n",
    "\n",
    "rects1 = plt.bar(index + bar_width*-2, acc_list, bar_width, label=\"Accuracy\")\n",
    "rects2 = plt.bar(index + bar_width*-1, rec_list, bar_width, label=\"Recall\")\n",
    "rects3 = plt.bar(index + bar_width*0, pre_list, bar_width, label=\"Precision\")\n",
    "rects4 = plt.bar(index + bar_width*1, f1_list, bar_width, label=\"F1\")\n",
    "\n",
    "plt.xlabel(\"Loss and Accuracy\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title('C-UNet++ performance on various images type')\n",
    "plt.xticks(index, name_list)\n",
    "plt.legend()\n",
    "\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "ax.bar_label(rects3, padding=3)\n",
    "ax.bar_label(rects4, padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/home/alan/Documents/Cloud_Detection/Performance bar chart (hinge loss).png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [\"\", \"No Cloud\", \"Less Cloud\", \"More Cloud\", \"Full Cloud\", \"Thin Cloud\", \"Thick Cloud\"]\n",
    "s = np.asarray([ name, \n",
    "                 [\"Accuracy\"] + acc_list, \n",
    "                 [\"Recall\"] + rec_list, \n",
    "                 [\"Precision\"] + pre_list, \n",
    "                 [\"F1\"] + f1_list ])\n",
    "np.savetxt(\"/home/alan/Documents/import.csv\", s, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv1.weight: 13.54%\n",
      "Sparsity in conv1.weight: 16.56%\n",
      "Sparsity in conv1.weight: 14.71%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.upconv1[0].weight == 0))\n",
    "        / float(model.upconv1[0].weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.upconv2[0].weight == 0))\n",
    "        / float(model.upconv2[0].weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.upconv3[0].weight == 0))\n",
    "        / float(model.upconv3[0].weight.nelement())\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20691811052c47fbc34c1dc9ea0ef9ffbf39295de040bf9203c02406b7e5dacf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

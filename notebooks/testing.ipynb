{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = r\"C:\\Users\\hdmqu\\Downloads\\C-FCN.pth\"\n",
    "RED_PATH   = r\"C:\\Users\\hdmqu\\Documents\\GitHub\\Cloud_Detection\\data\\95-cloud\\train_red_additional_to38cloud\"\n",
    "\n",
    "r_dir = Path(RED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   0%      1 - 30%    30 - 70%    70 - 100%\n",
    "no_cloud, less_cloud, more_cloud, full_cloud = [], [], [], []\n",
    "\n",
    "low_threshold = 384*384 * 0.3\n",
    "high_threshold = 384*384 * 0.7\n",
    "\n",
    "GT_PATH = RED_PATH.replace(\"red\", \"gt\")\n",
    "u = os.listdir(GT_PATH)\n",
    "\n",
    "for file in u[int(len(u)/2):]:\n",
    "    img = cv2.imread(os.path.join(GT_PATH, file)) \n",
    "    \n",
    "    occurrences = np.count_nonzero(img[:, :, 0] == 255)\n",
    "\n",
    "    if occurrences == 0:\n",
    "        no_cloud.append(file)\n",
    "        continue\n",
    "    elif occurrences < low_threshold:\n",
    "        less_cloud.append(file)\n",
    "        continue\n",
    "    elif occurrences < high_threshold:\n",
    "        more_cloud.append(file)\n",
    "    else:\n",
    "        full_cloud.append(file)\n",
    "\n",
    "print(\"No cloud images:\\t\",   len(no_cloud))\n",
    "print(\"Less cloud images:\\t\", len(less_cloud))\n",
    "print(\"More cloud images:\\t\", len(more_cloud))\n",
    "print(\"Full cloud images:\\t\", len(full_cloud))\n",
    "print(\"Total images:\\t\\t\", int(len(os.listdir(RED_PATH))/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, file_list):\n",
    "        super().__init__()\n",
    "        self.files = [self.combine_files(f) for f in self.to_path(file_list) if not os.path.isdir(f)]\n",
    "        \n",
    "    def to_path(self, list):\n",
    "        for i in range(len(list)):\n",
    "            list[i] = os.path.join(RED_PATH, list[i].replace(\"gt\", \"red\"))\n",
    "        return list\n",
    "        \n",
    "    def combine_files(self, r_file: Path):\n",
    "        files = {\n",
    "            'red'  : r_file, \n",
    "            'green': r_file.replace('red', 'green'),\n",
    "            'blue' : r_file.replace('red', 'blue'), \n",
    "            'nir'  : r_file.replace('red', 'nir'),\n",
    "            'gt'   : r_file.replace('red', 'gt')\n",
    "        }\n",
    "        return files\n",
    "                                       \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "     \n",
    "    def open_as_array(self, idx, invert=False, include_nir=False):\n",
    "        raw_rgb = np.stack([\n",
    "            np.array(Image.open(self.files[idx]['red'])),\n",
    "            np.array(Image.open(self.files[idx]['green'])),\n",
    "            np.array(Image.open(self.files[idx]['blue'])),\n",
    "        ], axis=2)\n",
    "        if include_nir:\n",
    "            nir = np.expand_dims(np.array(Image.open(self.files[idx]['nir'])), 2)\n",
    "            raw_rgb = np.concatenate([raw_rgb, nir], axis=2)\n",
    "        if invert:\n",
    "            raw_rgb = raw_rgb.transpose((2,0,1))\n",
    "        return (raw_rgb / np.iinfo(raw_rgb.dtype).max) # normalized\n",
    "\n",
    "\n",
    "    def open_mask(self, idx, add_dims=False):\n",
    "        raw_mask = np.array(Image.open(self.files[idx]['gt']))\n",
    "        raw_mask = np.where(raw_mask==255, 1, 0)\n",
    "        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.open_as_array(idx, invert=True), dtype=torch.float32)\n",
    "        y = torch.tensor(self.open_mask(idx, add_dims=False), dtype=torch.long)\n",
    "        return x, y\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Dataset class with {self.__len__()} files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cloud_data   =  CloudDataset(no_cloud)\n",
    "less_cloud_data =  CloudDataset(less_cloud)\n",
    "more_cloud_data =  CloudDataset(more_cloud)\n",
    "full_cloud_data =  CloudDataset(full_cloud)\n",
    "\n",
    "print(no_cloud_data)\n",
    "print(less_cloud_data)\n",
    "print(more_cloud_data)\n",
    "print(full_cloud_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single input example\n",
    "x, y = no_cloud_data[0]\n",
    "print(f'Image: {x.shape}')\n",
    "print(f'Mask: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class C_FCN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = self.contract_block(in_channels, 5)\n",
    "        self.conv2 = self.contract_block(5, 2)\n",
    "    \n",
    "        self.out   = self.output_block(2, out_channels)\n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # downsampling part\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        \n",
    "        out   = self.out(conv2)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def contract_block(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        contract = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        )\n",
    "        return contract\n",
    "    \n",
    "    def output_block(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        out = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 2, kernel_size=kernel_size, padding=padding),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(2, 2, kernel_size=1, padding=0),\n",
    "            nn.Sigmoid(),\n",
    "            nn.ConvTranspose2d(2, out_channels, stride=4, kernel_size=4, padding=0)\n",
    "        )\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    batch = list(filter (lambda x:torch.sum(x[0]).item() != 0, batch))\n",
    "    if len(batch) == 0:\n",
    "        print(\"DOOOOO\")\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKER = 0\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using {DEVICE} device.\")\n",
    "\n",
    "model = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "model.to(DEVICE)\n",
    "\n",
    "no_cloud_loader   = DataLoader(no_cloud_data,   BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER, collate_fn=my_collate)\n",
    "less_cloud_loader = DataLoader(less_cloud_data, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER, collate_fn=my_collate)\n",
    "more_cloud_loader = DataLoader(more_cloud_data, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER, collate_fn=my_collate)\n",
    "full_cloud_loader = DataLoader(full_cloud_data, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "def get_accuracy(data_loader, model):\n",
    "    acc, rec, pre, f1 = [], [], [], []\n",
    "\n",
    "    accuracy  = torchmetrics.Accuracy()\n",
    "    recall    = torchmetrics.Recall()\n",
    "    precision = torchmetrics.Precision()\n",
    "    f1_score  = torchmetrics.F1Score()\n",
    "\n",
    "\n",
    "    for images, targets in tqdm(data_loader):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Get predictions\n",
    "            images = images.to(DEVICE).to(torch.float32)\n",
    "            targets = targets.to(DEVICE)\n",
    "            predictions = model(images)[:, 0, :, :].to(torch.float32)\n",
    "\n",
    "            acc.append(accuracy(predictions, targets))\n",
    "            rec.append(recall(predictions, targets))\n",
    "            pre.append(precision(predictions, targets))\n",
    "            f1.append(f1_score(predictions, targets))\n",
    "\n",
    "    #return round(np.mean(acc), 4), round(np.mean(rec)), round(np.mean(pre), 4), round(np.mean(f1), 4)\n",
    "    return np.mean(acc), np.mean(rec), np.mean(pre), np.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_acc,   no_rec,   no_pre,   no_f1   = get_accuracy(no_cloud_loader,   model)\n",
    "less_acc, less_rec, less_pre, less_f1 = get_accuracy(less_cloud_loader, model)\n",
    "more_acc, more_rec, more_pre, more_f1 = get_accuracy(more_cloud_loader, model)\n",
    "full_acc, full_rec, full_pre, full_f1 = get_accuracy(full_cloud_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t\\tAccuracy\\tRecall\\t\\tPrecision\\tF1\")\n",
    "print(f\"No cloud:\\t{no_acc}\\t{no_rec}\\t{no_pre}\\t{no_f1}\")\n",
    "print(f\"Less cloud:\\t{less_acc}\\t{less_rec}\\t{less_pre}\\t{less_f1}\")\n",
    "print(f\"More cloud:\\t{more_acc}\\t{more_rec}\\t{more_pre}\\t{more_f1}\")\n",
    "print(f\"Full cloud:\\t{full_acc}\\t{full_rec}\\t{full_pre}\\t{full_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloud thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thin_cloud, thick_cloud = [], []\n",
    "\n",
    "thickness_threshold = (0.46875, 0.46875, 0.46875, 0.46875)\n",
    "\n",
    "for i in range(len(full_cloud_data)):\n",
    "\n",
    "    x, y = full_cloud_data[i]\n",
    "    out = cv2.inRange(torch.permute(x, (1, 2, 0)).numpy(), thickness_threshold, (1, 1, 1, 1))\n",
    "\n",
    "    try:\n",
    "        IoU = np.sum(np.logical_and(out, y.numpy())) / np.sum(np.logical_or(out, y.numpy()))\n",
    "    except ZeroDivisionError:\n",
    "        thin_cloud.append(full_cloud[i])\n",
    "        continue\n",
    "\n",
    "    if IoU > 0.5:\n",
    "        thick_cloud.append(full_cloud[i])\n",
    "    else:\n",
    "        thin_cloud.append(full_cloud[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thin_cloud_data  =  CloudDataset(thin_cloud)\n",
    "thick_cloud_data =  CloudDataset(thick_cloud)\n",
    "\n",
    "print(thin_cloud)\n",
    "print(thick_cloud)\n",
    "\n",
    "thin_cloud_loader  = DataLoader(thin_cloud_data,  BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER, collate_fn=my_collate)\n",
    "thick_cloud_loader = DataLoader(thick_cloud_data, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thin_acc,  thin_rec,  thin_pre,  thin_f1  = get_accuracy(thin_cloud_loader,  model)\n",
    "thick_acc, thick_rec, thick_pre, thick_f1 = get_accuracy(thick_cloud_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t\\tAccuracy\\tRecall\\t\\tPrecision\\tF1\")\n",
    "print(f\"Thin cloud:\\t{thin_acc}\\t{thin_rec}\\t{thin_pre}\\t{thin_f1}\")\n",
    "print(f\"Thick cloud:\\t{thick_acc}\\t{thick_rec}\\t{thick_pre}\\t{thick_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [\"\", \"No Cloud\", \"Less Cloud\", \"More Cloud\", \"Full Cloud\", \"Thin Cloud\", \"Thick Cloud\"]\n",
    "s = np.asarray([ name, \n",
    "                 [\"Accuracy\"]  + [no_acc, less_acc, more_acc, full_acc, thin_acc, thick_acc], \n",
    "                 [\"Recall\"]    + [no_rec, less_rec, more_rec, full_rec, thin_rec, thick_rec], \n",
    "                 [\"Precision\"] + [no_pre, less_pre, more_pre, full_pre, thin_pre, thick_pre], \n",
    "                 [\"F1\"]        + [no_f1,  less_f1,  more_f1,  full_f1,  thin_f1,  thick_f1]])\n",
    "np.savetxt(r\".\\Cloud_Detection\\import.csv\", s, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(pred):\n",
    "    mask_pred = np.zeros([384,384,3])\n",
    "    mask_pred[:,:,0] = pred[:,0,:,:] * 255\n",
    "    mask_pred[:,:,1] = pred[:,1,:,:] * 255\n",
    "    return mask_pred\n",
    "\n",
    "images = [\n",
    "    no_cloud_data[16],\n",
    "    less_cloud_data[26],\n",
    "    more_cloud_data[26],\n",
    "    full_cloud_data[23]\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(3, len(images), figsize=(18, 10))\n",
    "\n",
    "i = 0\n",
    "import cv2\n",
    "\n",
    "for image in images:\n",
    "    # Retrieve and format results\n",
    "    display_im = image[0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    pred = model(image[0].unsqueeze(0)).cpu().detach().numpy()\n",
    "    pred = get_mask(pred)\n",
    "    mask = image[1]\n",
    "    \n",
    "    # Display\n",
    "    axs[0][i].imshow(display_im)\n",
    "    axs[0][i].set_title('Image')\n",
    "    axs[1][i].imshow(mask)\n",
    "    axs[1][i].set_title('Ground Truth')\n",
    "    axs[2][i].imshow(np.array(pred).astype(int))\n",
    "    axs[2][i].set_title('Predicted Mask')\n",
    "    \n",
    "    # Increment count\n",
    "    i += 1\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a19255f787a6cc652b4d0a1e2bea561a9d91dd69cbdbda30c9cbfc7f2deccdd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
